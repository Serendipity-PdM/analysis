{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"behrad3d/nasa-cmaps\")\n",
    "#print(\"Path to dataset files:\", path)\n",
    "\n",
    "DATA_PATH = Path(\"datasets/CMaps/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FD00X dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = ['unit_number', 'time_cycles']\n",
    "settings = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensors = ['s_{}'.format(i+1) for i in range(0,21)]\n",
    "COLS = indexes + settings + sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fd_dataset(dataset_id):\n",
    "    \"\"\"\n",
    "    Load train/test/RUL files for a single FD dataset (e.g., FD001, FD002, etc.)\n",
    "    \n",
    "    :param dataset_id: integer 1..4, e.g. for FD001 use dataset_id=1\n",
    "    :return: df_train, df_test, df_rul (pandas DataFrames)\n",
    "    \"\"\"\n",
    "\n",
    "    train_file = DATA_PATH / f\"train_FD00{dataset_id}.txt\"\n",
    "    test_file  = DATA_PATH / f\"test_FD00{dataset_id}.txt\"\n",
    "    rul_file   = DATA_PATH / f\"RUL_FD00{dataset_id}.txt\"\n",
    "\n",
    "    df_train = pd.read_csv(\n",
    "        train_file,\n",
    "        sep=r\"\\s+\",        \n",
    "        header=None,\n",
    "        names=COLS,\n",
    "        index_col=False\n",
    "    )\n",
    "\n",
    "    df_test = pd.read_csv(\n",
    "        test_file,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=COLS,\n",
    "        index_col=False\n",
    "    )\n",
    "\n",
    "    df_rul = pd.read_csv(\n",
    "        rul_file,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=[\"RUL\"],\n",
    "        index_col=False\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test, df_rul\n",
    "\n",
    "def add_train_rul(df_train):\n",
    "    \"\"\"\n",
    "    For the training set, calculate RUL for every row.\n",
    "    NASAâ€™s train data runs each engine to failure, so:\n",
    "      RUL = (last cycle for that engine) - (current cycle).\n",
    "    \"\"\"\n",
    "    # Group by unit and get the max cycle of each engine\n",
    "    max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(max)\n",
    "    # RUL = distance to max cycle\n",
    "    df_train[\"RUL\"] = max_cycle - df_train[\"time_cycles\"]\n",
    "    return df_train\n",
    "\n",
    "def add_test_rul(df_test, df_rul):\n",
    "    \"\"\"\n",
    "    For the test set, each engine is truncated before failure. \n",
    "    NASA gives a single RUL for the *last* row of each engine in df_rul.\n",
    "    \n",
    "    Typically, we only need that final row to evaluate or predict RUL. \n",
    "    So we can 'merge' that RUL onto the final snapshot of each engine.\n",
    "    \n",
    "    If you want row-level RUL for the entire partial test run (less common),\n",
    "    you need a different approach. Usually, we label only the last row.\n",
    "    \"\"\"\n",
    "    # Identify the final row for each engine in the test set\n",
    "    # i.e., the row with the maximum 'time_cycles' for that unit_number\n",
    "    idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(max) == df_test[\"time_cycles\"]\n",
    "    final_test_rows = df_test[idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Attach RUL from df_rul, which is one row per engine\n",
    "    # RUL rows match by index => engine 1 => df_rul.loc[0], engine 2 => df_rul.loc[1], etc.\n",
    "    # final_test_rows are also in ascending engine order, so we can do direct assignment\n",
    "    final_test_rows[\"RUL\"] = df_rul[\"RUL\"]\n",
    "    \n",
    "    return final_test_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3290/1092342981.py:46: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(max)\n",
      "/tmp/ipykernel_3290/1092342981.py:64: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(max) == df_test[\"time_cycles\"]\n",
      "/tmp/ipykernel_3290/1092342981.py:46: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(max)\n",
      "/tmp/ipykernel_3290/1092342981.py:64: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(max) == df_test[\"time_cycles\"]\n",
      "/tmp/ipykernel_3290/1092342981.py:46: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(max)\n",
      "/tmp/ipykernel_3290/1092342981.py:64: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(max) == df_test[\"time_cycles\"]\n",
      "/tmp/ipykernel_3290/1092342981.py:46: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(max)\n",
      "/tmp/ipykernel_3290/1092342981.py:64: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(max) == df_test[\"time_cycles\"]\n"
     ]
    }
   ],
   "source": [
    "datasets = {}  \n",
    "\n",
    "for i in range(1, 5):\n",
    "    \n",
    "    df_train_raw, df_test_raw, df_rul = load_fd_dataset(i)\n",
    "    df_train = add_train_rul(df_train_raw)\n",
    "    df_test_final = add_test_rul(df_test_raw, df_rul)\n",
    "    key = f\"FD00{i}\"\n",
    "    datasets[key] = {\n",
    "        \"train\":       df_train,   \n",
    "        \"test\":        df_test_raw,\n",
    "        \"rul\":         df_rul,\n",
    "        \"test_final\":  df_test_final,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
