{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"behrad3d/nasa-cmaps\")\n",
    "#print(\"Path to dataset files:\", path)\n",
    "\n",
    "DATA_PATH = Path(\"datasets/CMaps/\")\n",
    "images_dir = \"images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FD00X dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = ['unit_number', 'time_cycles']\n",
    "settings = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensors = ['s_{}'.format(i+1) for i in range(0,21)]\n",
    "COLS = indexes + settings + sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor_dictionary = {}\n",
    "dict_list = [\n",
    "    \"Fan intake temperature (°R)\",\n",
    "    \"Low-Pressure Compressor outlet temperature (°R)\",\n",
    "    \"High-Pressure Compressor outlet temperature (°R)\",\n",
    "    \"Low-Pressure Turbine outlet temperature (°R)\",\n",
    "    \"Fan intake pressure (psia)\",\n",
    "    \"Bypass-duct pressure (psia)\",\n",
    "    \"High-Pressure Compressor outlet pressure (psia)\",\n",
    "    \"Physical fan RPM\",\n",
    "    \"Physical core RPM\",\n",
    "    \"Engine pressure ratio (P50/P2)\",\n",
    "    \"High-Pressure Compressor outlet static pressure (psia)\",\n",
    "    \"Fuel flow to Ps30 ratio (pps/psia)\",\n",
    "    \"Corrected fan RPM\",\n",
    "    \"Corrected core RPM\",\n",
    "    \"Bypass ratio\",\n",
    "    \"Burner fuel-air ratio\",\n",
    "    \"Bleed enthalpy\",\n",
    "    \"Required fan RPM\",\n",
    "    \"Required fan conversion RPM\",\n",
    "    \"High-pressure turbine cooling airflow\",\n",
    "    \"Low-pressure turbine cooling airflow\"\n",
    "]\n",
    "\n",
    "Sensor_dictionary = {f's_{i+1}': sensor for i, sensor in enumerate(dict_list)}\n",
    "Sensor_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fd_dataset(dataset_id):\n",
    "    \"\"\"\n",
    "    Load train/test/RUL files for a single FD dataset (e.g., FD001, FD002, etc.)\n",
    "    \n",
    "    :param dataset_id: integer 1..4, e.g. for FD001 use dataset_id=1\n",
    "    :return: df_train, df_test, df_rul (pandas DataFrames)\n",
    "    \"\"\"\n",
    "\n",
    "    train_file = DATA_PATH / f\"train_FD00{dataset_id}.txt\"\n",
    "    test_file  = DATA_PATH / f\"test_FD00{dataset_id}.txt\"\n",
    "    rul_file   = DATA_PATH / f\"RUL_FD00{dataset_id}.txt\"\n",
    "\n",
    "    df_train = pd.read_csv(\n",
    "        train_file,\n",
    "        sep=r\"\\s+\",        \n",
    "        header=None,\n",
    "        names=COLS,\n",
    "        index_col=False\n",
    "    )\n",
    "\n",
    "    df_test = pd.read_csv(\n",
    "        test_file,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=COLS,\n",
    "        index_col=False\n",
    "    )\n",
    "\n",
    "    df_rul = pd.read_csv(\n",
    "        rul_file,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=[\"RUL\"],\n",
    "        index_col=False\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test, df_rul\n",
    "\n",
    "def add_train_rul(df_train):\n",
    "    \"\"\"\n",
    "    For the training set, calculate RUL for every row.\n",
    "    NASA’s train data runs each engine to failure, so:\n",
    "      RUL = (last cycle for that engine) - (current cycle).\n",
    "    \"\"\"\n",
    "    # Group by unit and get the max cycle of each engine\n",
    "    max_cycle = df_train.groupby(\"unit_number\")[\"time_cycles\"].transform(\"max\")\n",
    "    # RUL = distance to max cycle\n",
    "    df_train[\"RUL\"] = max_cycle - df_train[\"time_cycles\"]\n",
    "    return df_train\n",
    "\n",
    "def add_test_rul(df_test, df_rul):\n",
    "    \"\"\"\n",
    "    For the test set, each engine is truncated before failure. \n",
    "    NASA gives a single RUL for the *last* row of each engine in df_rul.\n",
    "    \n",
    "    Typically, we only need that final row to evaluate or predict RUL. \n",
    "    So we can 'merge' that RUL onto the final snapshot of each engine.\n",
    "    \n",
    "    If you want row-level RUL for the entire partial test run (less common),\n",
    "    you need a different approach. Usually, we label only the last row.\n",
    "    \"\"\"\n",
    "    # Identify the final row for each engine in the test set\n",
    "    # i.e., the row with the maximum 'time_cycles' for that unit_number\n",
    "    idx = df_test.groupby(\"unit_number\")[\"time_cycles\"].transform(\"max\") == df_test[\"time_cycles\"]\n",
    "    final_test_rows = df_test[idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Attach RUL from df_rul, which is one row per engine\n",
    "    # RUL rows match by index => engine 1 => df_rul.loc[0], engine 2 => df_rul.loc[1], etc.\n",
    "    # final_test_rows are also in ascending engine order, so we can do direct assignment\n",
    "    final_test_rows[\"RUL\"] = df_rul[\"RUL\"]\n",
    "    \n",
    "    return final_test_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "datasets = {}  \n",
    "\n",
    "for i in range(1, 5):\n",
    "    \n",
    "    df_train_raw, df_test_raw, df_rul = load_fd_dataset(i)\n",
    "    df_train = add_train_rul(df_train_raw)\n",
    "    df_test_final = add_test_rul(df_test_raw, df_rul)\n",
    "    key = f\"FD00{i}\"\n",
    "    datasets[key] = {\n",
    "        \"train\":       df_train,   \n",
    "        \"test\":        df_test_raw,\n",
    "        \"rul\":         df_rul,\n",
    "        \"test_final\":  df_test_final,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name, ds_dict in datasets.items():\n",
    "    print(ds_name)\n",
    "    print(\"  train shape:\", ds_dict[\"train\"].shape, \"(includes computed RUL)\")\n",
    "    print(\"  test shape: \", ds_dict[\"test\"].shape)\n",
    "    print(\"  rul shape:  \", ds_dict[\"rul\"].shape, \"(one row per engine in test)\")\n",
    "    print(\"  final test shape (with RUL):\", ds_dict[\"test_final\"].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"FD001\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"FD001\"][\"train\"].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create distribution plot of max cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name, ds_dict in datasets.items():\n",
    "    df_train = ds_dict[\"train\"]\n",
    "    fig_name = os.path.join(images_dir, f\"{ds_name}_displot.png\")\n",
    "    \n",
    "    if os.path.exists(fig_name):\n",
    "        continue\n",
    "\n",
    "    max_time_cycles = df_train.groupby(\"unit_number\")[\"time_cycles\"].max()\n",
    "    sns.displot(\n",
    "        data=max_time_cycles, \n",
    "        kde=True,\n",
    "        bins=20,\n",
    "        height=6,\n",
    "        aspect=2,\n",
    "    )\n",
    "    plt.xlabel(\"Max Time Cycle\")\n",
    "    plt.title(f\"Max Time Cycles Distribution – {ds_name}\", fontsize=14)\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create correlation_matrixes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name, ds_dict in datasets.items():\n",
    "    df_train = ds_dict[\"train\"]\n",
    "    fig_name = os.path.join(images_dir, f\"{ds_name}_corr_heatmap.png\")\n",
    "\n",
    "    if os.path.exists(fig_name):\n",
    "        continue\n",
    "\n",
    "    corr = df_train.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        cmap=cmap,\n",
    "        vmax=.3,\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\"shrink\": .5},\n",
    "        annot=True,\n",
    "        fmt=\".2f\"\n",
    "    )\n",
    "    plt.title(f\"Correlation Matrix Heatmap – {ds_name}\", fontsize=14)\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_dir = os.path.join(images_dir, \"signal_plots\")\n",
    "os.makedirs(signal_dir, exist_ok=True)\n",
    "def plot_signal(df, Sensor_dic, signal_name, ds_name, images_dir):\n",
    "    fig_name = os.path.join(signal_dir, f\"{ds_name}_{signal_name}.png\")\n",
    "    if os.path.exists(fig_name):\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for i in df['unit_number'].unique():\n",
    "        if (i % 10 == 0):\n",
    "            plt.plot('RUL', signal_name, data=df[df['unit_number']==i].rolling(10).mean())\n",
    "\n",
    "    plt.xlim(250, 0)\n",
    "    plt.xticks(np.arange(0, 300, 25))\n",
    "    plt.ylabel(Sensor_dic[signal_name])\n",
    "    plt.xlabel('Remaining Useful Life')\n",
    "    plt.title(f'{signal_name} - {ds_name}')\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "for ds_name, ds_dict in datasets.items():\n",
    "    df_train = ds_dict[\"train\"]\n",
    "    for i in range(1, 22):\n",
    "        signal_name = f's_{i}'\n",
    "        try:\n",
    "            plot_signal(df_train, Sensor_dictionary, signal_name, ds_name, images_dir)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_dir = os.path.join(images_dir, \"box_plots\")\n",
    "os.makedirs(boxplot_dir, exist_ok=True)\n",
    "\n",
    "for ds_name, ds_dict in datasets.items():\n",
    "    df_train = ds_dict[\"train\"]\n",
    "    \n",
    "    for i in range(1, 22):\n",
    "        signal_name = f's_{i}'\n",
    "        fig_name = os.path.join(boxplot_dir, f\"{ds_name}_{signal_name}_boxplot.png\")\n",
    "        \n",
    "        if os.path.exists(fig_name):\n",
    "            print(f\"Skipping {fig_name}, already exists.\")\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        sns.boxplot(x=\"unit_number\", y=signal_name, data=df_train)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(f\"Box Plot of {signal_name} by Unit – {ds_name}\")\n",
    "        plt.xlabel(\"Unit Number\")\n",
    "        plt.ylabel(Sensor_dictionary.get(signal_name, signal_name))  # fallback to raw name\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_name)\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
