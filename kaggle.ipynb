{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gets the dataset from kaggle and put it inside a temprorary location\n",
    "https://www.kaggle.com/datasets/hiimanshuagarwal/predictive-maintenance-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"hiimanshuagarwal/predictive-maintenance-dataset\")+ \"/predictive_maintenance_dataset.csv\"\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values to worry about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['failure'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date')['failure'].resample('D').sum().plot()\n",
    "plt.title(\"Failures Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df[['failure', 'metric1', 'metric2', 'metric3', 'metric4', 'metric5', 'metric6', 'metric7', 'metric8', 'metric9']].corr()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, annot=True, fmt='.2f', cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.title('Correlation Matrix for Predictive Maintenance Features', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('correlation_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"metric7\"]== df[\"metric8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric7 and metric 8 might be redundant, metric 8/7 has the strongest correlation also metric 2 and metric 4  might help.\n",
    "it might be a good idea to remove metrics with low correlation from the dataset before creating the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A p-value represents the probability of observing a correlation as strong as the one in your sample (or stronger) if there was actually no correlation in the overall population (i.e., if the null hypothesis is true).\n",
    "How to interpret p-values:\n",
    "\n",
    "p < 0.05: Traditionally considered statistically significant. This means there's less than a 5% chance you would observe this correlation if no true relationship exists.\n",
    "p < 0.01: Strongly significant\n",
    "p < 0.001: Very strongly significant\n",
    "\n",
    "t = r * sqrt((n-2)/(1-rÂ²))\n",
    "- r is the correlation coefficient\n",
    "- n is the sample size (124494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "n = 124494\n",
    "r = 0.12\n",
    "\n",
    "# Calculate t-statistic\n",
    "t = r * math.sqrt((n-2)/(1-r**2))\n",
    "\n",
    "# Calculate two-tailed p-value\n",
    "p = 2 * (1 - stats.t.cdf(abs(t), df=n-2))\n",
    "\n",
    "print(f\"t-statistic: {t}\")\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the p value is so small that python rounds it to zero.\n",
    "this mean even the metrics with smallest correlation is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
